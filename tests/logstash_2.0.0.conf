input {
    stdin { } # logstash stops when input is closed
}

filter {
    grok {

        add_field => {
            "received_at" => "%{@timestamp}"
            "received_from" => "%{@source_host}"
        }

        break_on_match => true
        named_captures_only => true
        patterns_dir => [ "/tmp/logpatterns-groktest" ]

        match => {
            "message" => "%{RSYSLOGCUSTOM}"
        }
    }

    kv {
        source => "KEY_EQ_VALUEDATA"
    }

    date {
        match => [ "syslog_timestamp", "yyyy-MM-dd'T'HH:mm:ss.SSSSSSZZ", "yyyy-MM-dd'T'HH:mm:ssZZ", "yyyy-MM-dd HH:mm:ss.SSSSSS" ]
    }

    if ("exclude_tags" not in [tags]) {
        mutate {
            replace => {
                "@source_host" => "%{syslog_hostname}"
                "@message" => "%{syslog_message}"
            }
        }
    }

    if ("_grokparsefailure" not in [tags]) {
        mutate {
            remove_field => [ "syslog_hostname", "syslog_message", "syslog_timestamp", "KEY_EQ_VALUEDATA" ]
            convert => { "wrf_success" => "boolean" }
        }
    }

    bytes2human {
        convert => {
            "volumedata" => "bytes"
            "volumeused" => "bytes"
            "volumeavail" => "bytes"
            "volumetotal" => "bytes"
            "objrecovthr" => "bytes"
            "actwrite" => "bytes"
            "actread" => "bytes"
        }
    }

    mutate {
        convert => {
            "volumedata" => "integer"
            "volumeused" => "integer"
            "volumeavail" => "integer"
            "volumetotal" => "integer"
            "objrecovthr" => "integer"
            "actwrite" => "integer"
            "actread" => "integer"
        }
    }
}

output {
  stdout { codec => json_lines } # add newline per output
}
